{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1faeded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51705eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>type</th>\n",
       "      <th>1007_s_at</th>\n",
       "      <th>1053_at</th>\n",
       "      <th>117_at</th>\n",
       "      <th>121_at</th>\n",
       "      <th>1255_g_at</th>\n",
       "      <th>1294_at</th>\n",
       "      <th>1316_at</th>\n",
       "      <th>1320_at</th>\n",
       "      <th>...</th>\n",
       "      <th>AFFX-r2-Ec-bioD-3_at</th>\n",
       "      <th>AFFX-r2-Ec-bioD-5_at</th>\n",
       "      <th>AFFX-r2-P1-cre-3_at</th>\n",
       "      <th>AFFX-r2-P1-cre-5_at</th>\n",
       "      <th>AFFX-ThrX-3_at</th>\n",
       "      <th>AFFX-ThrX-5_at</th>\n",
       "      <th>AFFX-ThrX-M_at</th>\n",
       "      <th>AFFX-TrpnX-3_at</th>\n",
       "      <th>AFFX-TrpnX-5_at</th>\n",
       "      <th>AFFX-TrpnX-M_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84</td>\n",
       "      <td>basal</td>\n",
       "      <td>9.850040</td>\n",
       "      <td>8.097927</td>\n",
       "      <td>6.424728</td>\n",
       "      <td>7.353027</td>\n",
       "      <td>3.029122</td>\n",
       "      <td>6.880079</td>\n",
       "      <td>4.963740</td>\n",
       "      <td>4.408328</td>\n",
       "      <td>...</td>\n",
       "      <td>12.229711</td>\n",
       "      <td>11.852955</td>\n",
       "      <td>13.658701</td>\n",
       "      <td>13.477698</td>\n",
       "      <td>6.265781</td>\n",
       "      <td>5.016196</td>\n",
       "      <td>4.901594</td>\n",
       "      <td>2.966657</td>\n",
       "      <td>3.508495</td>\n",
       "      <td>3.301999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>basal</td>\n",
       "      <td>9.861357</td>\n",
       "      <td>8.212222</td>\n",
       "      <td>7.062593</td>\n",
       "      <td>7.685578</td>\n",
       "      <td>3.149468</td>\n",
       "      <td>7.542283</td>\n",
       "      <td>5.129607</td>\n",
       "      <td>4.584418</td>\n",
       "      <td>...</td>\n",
       "      <td>12.178531</td>\n",
       "      <td>11.809408</td>\n",
       "      <td>13.750086</td>\n",
       "      <td>13.470146</td>\n",
       "      <td>6.771853</td>\n",
       "      <td>5.291005</td>\n",
       "      <td>5.405839</td>\n",
       "      <td>2.934763</td>\n",
       "      <td>3.687666</td>\n",
       "      <td>3.064299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>basal</td>\n",
       "      <td>10.103478</td>\n",
       "      <td>8.936137</td>\n",
       "      <td>5.735970</td>\n",
       "      <td>7.687822</td>\n",
       "      <td>3.125931</td>\n",
       "      <td>6.562369</td>\n",
       "      <td>4.813449</td>\n",
       "      <td>4.425195</td>\n",
       "      <td>...</td>\n",
       "      <td>12.125108</td>\n",
       "      <td>11.725766</td>\n",
       "      <td>13.621732</td>\n",
       "      <td>13.295080</td>\n",
       "      <td>6.346952</td>\n",
       "      <td>5.171403</td>\n",
       "      <td>5.184286</td>\n",
       "      <td>2.847684</td>\n",
       "      <td>3.550597</td>\n",
       "      <td>3.158535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>basal</td>\n",
       "      <td>9.756875</td>\n",
       "      <td>7.357148</td>\n",
       "      <td>6.479183</td>\n",
       "      <td>6.986624</td>\n",
       "      <td>3.181638</td>\n",
       "      <td>7.802344</td>\n",
       "      <td>5.490982</td>\n",
       "      <td>4.567956</td>\n",
       "      <td>...</td>\n",
       "      <td>12.111235</td>\n",
       "      <td>11.719215</td>\n",
       "      <td>13.743108</td>\n",
       "      <td>13.508861</td>\n",
       "      <td>6.610284</td>\n",
       "      <td>5.193356</td>\n",
       "      <td>5.086569</td>\n",
       "      <td>3.031602</td>\n",
       "      <td>3.524981</td>\n",
       "      <td>3.272665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>basal</td>\n",
       "      <td>9.408330</td>\n",
       "      <td>7.746404</td>\n",
       "      <td>6.693980</td>\n",
       "      <td>7.333426</td>\n",
       "      <td>3.169923</td>\n",
       "      <td>7.610457</td>\n",
       "      <td>5.372469</td>\n",
       "      <td>4.424426</td>\n",
       "      <td>...</td>\n",
       "      <td>12.173642</td>\n",
       "      <td>11.861296</td>\n",
       "      <td>13.797774</td>\n",
       "      <td>13.542206</td>\n",
       "      <td>6.414354</td>\n",
       "      <td>5.040202</td>\n",
       "      <td>5.235318</td>\n",
       "      <td>2.956232</td>\n",
       "      <td>3.445501</td>\n",
       "      <td>3.193947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   samples   type  1007_s_at   1053_at    117_at    121_at  1255_g_at  \\\n",
       "0       84  basal   9.850040  8.097927  6.424728  7.353027   3.029122   \n",
       "1       85  basal   9.861357  8.212222  7.062593  7.685578   3.149468   \n",
       "2       87  basal  10.103478  8.936137  5.735970  7.687822   3.125931   \n",
       "3       90  basal   9.756875  7.357148  6.479183  6.986624   3.181638   \n",
       "4       91  basal   9.408330  7.746404  6.693980  7.333426   3.169923   \n",
       "\n",
       "    1294_at   1316_at   1320_at  ...  AFFX-r2-Ec-bioD-3_at  \\\n",
       "0  6.880079  4.963740  4.408328  ...             12.229711   \n",
       "1  7.542283  5.129607  4.584418  ...             12.178531   \n",
       "2  6.562369  4.813449  4.425195  ...             12.125108   \n",
       "3  7.802344  5.490982  4.567956  ...             12.111235   \n",
       "4  7.610457  5.372469  4.424426  ...             12.173642   \n",
       "\n",
       "   AFFX-r2-Ec-bioD-5_at  AFFX-r2-P1-cre-3_at  AFFX-r2-P1-cre-5_at  \\\n",
       "0             11.852955            13.658701            13.477698   \n",
       "1             11.809408            13.750086            13.470146   \n",
       "2             11.725766            13.621732            13.295080   \n",
       "3             11.719215            13.743108            13.508861   \n",
       "4             11.861296            13.797774            13.542206   \n",
       "\n",
       "   AFFX-ThrX-3_at  AFFX-ThrX-5_at  AFFX-ThrX-M_at  AFFX-TrpnX-3_at  \\\n",
       "0        6.265781        5.016196        4.901594         2.966657   \n",
       "1        6.771853        5.291005        5.405839         2.934763   \n",
       "2        6.346952        5.171403        5.184286         2.847684   \n",
       "3        6.610284        5.193356        5.086569         3.031602   \n",
       "4        6.414354        5.040202        5.235318         2.956232   \n",
       "\n",
       "   AFFX-TrpnX-5_at  AFFX-TrpnX-M_at  \n",
       "0         3.508495         3.301999  \n",
       "1         3.687666         3.064299  \n",
       "2         3.550597         3.158535  \n",
       "3         3.524981         3.272665  \n",
       "4         3.445501         3.193947  \n",
       "\n",
       "[5 rows x 54677 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\Downloads\\Breast_GSE45827.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "464ba87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "basal        41\n",
       "HER          30\n",
       "luminal_B    30\n",
       "luminal_A    29\n",
       "cell_line    14\n",
       "normal        7\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24525707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 54677)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[df['type'] != 'cell_line' ]\n",
    "new_df = new_df[new_df['type'] != 'normal']\n",
    "new_df.shape      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82e12b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='type', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9,9))\n",
    "sns.countplot(new_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54600cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.drop(['samples', 'type'],axis = 1)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(new_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e21673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e05abcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of data\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scaler = StandardScaler() \n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e507030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8846153846153846\n",
      "[[5 2 0 0]\n",
      " [0 8 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 1 5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled,y_train)\n",
    "print(model.score(X_train_scaled,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbf48d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8173076923076923\n",
      "0.7307692307692307\n",
      "[[5 3 0 0]\n",
      " [0 7 0 0]\n",
      " [0 0 6 4]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(model.score(X_train_scaled,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "922141db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8846153846153846\n",
      "[[5 2 0 0]\n",
      " [0 8 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 1 5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(model.score(X_train_scaled,y_train))\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65797de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8846153846153846\n",
      "[[4 1 0 0]\n",
      " [1 9 0 0]\n",
      " [0 0 5 0]\n",
      " [0 0 1 5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(model.score(X_train_scaled, y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5928aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11192213 0.1851001  0.23040978 0.27254999 0.30777403 0.33460666\n",
      " 0.35845937 0.37755736 0.39495494 0.41186522 0.42782081 0.44306471\n",
      " 0.45686886 0.47014236 0.48313362 0.49591789 0.50806984 0.51977854\n",
      " 0.53138894 0.54242796 0.5534401  0.56399284 0.57445563 0.58474735\n",
      " 0.59459041 0.60425323 0.61360672 0.62291966 0.63211212 0.64115458\n",
      " 0.65001981 0.65879562 0.66727261 0.67559373 0.68384181 0.69192232\n",
      " 0.69990818 0.70778192 0.71555728 0.7231829  0.73076041 0.73830785\n",
      " 0.74568595 0.75285665 0.75993333 0.76696397 0.77386947 0.78065798\n",
      " 0.78738744 0.79403259 0.80059398 0.80708669 0.81348064 0.81982958\n",
      " 0.82610358 0.83227325 0.83840877 0.84443748 0.85039618 0.85627503\n",
      " 0.86208587 0.8678616  0.87359981 0.87925913 0.88487876 0.89044414\n",
      " 0.89593838 0.9013429  0.90673459 0.9120524  0.91730634 0.92252526\n",
      " 0.92753728 0.93247492 0.93733988 0.94216303 0.94691974 0.9516646\n",
      " 0.95629414 0.96084396 0.96537604 0.96981883 0.97417249 0.978392\n",
      " 0.98247986 0.98640591 0.99019138 0.99373518 0.99696917 1.\n",
      " 1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 91).fit(X_train_scaled)\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "X_train_scaled_pca = pca.transform(X_train_scaled)\n",
    "X_test_scaled_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bfef602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8974358974358975\n",
      "[[10  3  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  0  9  1]\n",
      " [ 0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled_pca,y_train)\n",
    "print(model.score(X_train_scaled_pca,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled_pca)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab8a2535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7948717948717948\n",
      "[[ 7  0  0  0]\n",
      " [ 3 13  1  0]\n",
      " [ 0  0  6  1]\n",
      " [ 0  1  2  5]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_scaled_pca, y_train)\n",
    "print(model.score(X_train_scaled_pca,y_train))\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled_pca)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d0d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978494623655914\n",
      "{'n_estimators': 150, 'max_features': 'auto', 'max_depth': 12, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid_params = {\n",
    "    'n_estimators':[100,150,200,250,300,350,400,600],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'max_depth':[4,8,12,16,20,40],\n",
    "    'criterion':['gini','entropy']\n",
    "}\n",
    "\n",
    "gs = RandomizedSearchCV(\n",
    "    RandomForestClassifier(),\n",
    "    grid_params,\n",
    "    cv = 3\n",
    ")\n",
    "\n",
    "gs_results = gs.fit(X_train_scaled,y_train)\n",
    "print(gs_results.best_score_)\n",
    "print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "56d3f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9230769230769231\n",
      "[[10  3  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  0  9  0]\n",
      " [ 0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 150, max_features = 'auto', max_depth = 12, criterion = 'entropy')\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(model.score(X_train_scaled,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "589867ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.8784585  0.91156126        nan        nan 0.9451581         nan\n",
      "        nan 0.8784585         nan 0.8784585 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9451581027667985\n",
      "{'penalty': 'l2', 'max_iter': 400, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'penalty':['none','l2','l1','elasticnet'],\n",
    "    'max_iter':[100,300,400,500,600,700],\n",
    "    'C':[0.1,1,10,100]\n",
    "    \n",
    "}\n",
    "\n",
    "gs = RandomizedSearchCV(\n",
    "    LogisticRegression(),\n",
    "    grid_params,\n",
    "    cv = 4\n",
    ")\n",
    "\n",
    "gs_results = gs.fit(X_train_scaled,y_train)\n",
    "print(gs_results.best_score_)\n",
    "print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d512e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.8974358974358975\n",
      "[[10  3  0  0]\n",
      " [ 0 11  0  0]\n",
      " [ 0  0  9  1]\n",
      " [ 0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty = 'l2', max_iter = 400, C = 10)\n",
    "model.fit(X_train_scaled_pca,y_train)\n",
    "print(model.score(X_train_scaled_pca,y_train))\n",
    "\n",
    "y_pred = model.predict(X_test_scaled_pca)\n",
    "print(metrics.accuracy_score(y_test,y_pred))\n",
    "print(metrics.confusion_matrix(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085295db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
